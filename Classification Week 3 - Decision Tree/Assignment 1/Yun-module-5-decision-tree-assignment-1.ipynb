{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying safe loans with decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [LendingClub](https://www.lendingclub.com/) is a peer-to-peer leading company that directly connects borrowers and potential lenders/investors. In this notebook, you will build a classification model to predict whether or not a loan provided by LendingClub is likely to [default](https://en.wikipedia.org/wiki/Default_%28finance%29).\n",
    "\n",
    "In this notebook you will use data from the LendingClub to predict whether a loan will be paid off in full or the loan will be [charged off](https://en.wikipedia.org/wiki/Charge-off) and possibly go into default. In this assignment you will:\n",
    "\n",
    "* Use pandas to do some feature engineering.\n",
    "* Train a decision-tree on the LendingClub dataset.\n",
    "* Visualize the tree.\n",
    "* Predict whether a loan will default along with prediction probabilities (on a validation set).\n",
    "* Train a complex tree model and compare it to simple tree model.\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fire up Scikit-learn, Pandas and Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load LendingClub dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using a dataset from the [LendingClub](https://www.lendingclub.com/). A parsed and cleaned form of the dataset is availiable [here](https://github.com/learnml/machine-learning-specialization-private). Make sure you **download the dataset** before running the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yunpeng/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2698: DtypeWarning: Columns (19,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "loans = pd.read_csv('lending-club-data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring some features\n",
    "\n",
    "Let's quickly explore what the dataset looks like. First, let's print out the column names to see what features we have in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'member_id',\n",
       " 'loan_amnt',\n",
       " 'funded_amnt',\n",
       " 'funded_amnt_inv',\n",
       " 'term',\n",
       " 'int_rate',\n",
       " 'installment',\n",
       " 'grade',\n",
       " 'sub_grade',\n",
       " 'emp_title',\n",
       " 'emp_length',\n",
       " 'home_ownership',\n",
       " 'annual_inc',\n",
       " 'is_inc_v',\n",
       " 'issue_d',\n",
       " 'loan_status',\n",
       " 'pymnt_plan',\n",
       " 'url',\n",
       " 'desc',\n",
       " 'purpose',\n",
       " 'title',\n",
       " 'zip_code',\n",
       " 'addr_state',\n",
       " 'dti',\n",
       " 'delinq_2yrs',\n",
       " 'earliest_cr_line',\n",
       " 'inq_last_6mths',\n",
       " 'mths_since_last_delinq',\n",
       " 'mths_since_last_record',\n",
       " 'open_acc',\n",
       " 'pub_rec',\n",
       " 'revol_bal',\n",
       " 'revol_util',\n",
       " 'total_acc',\n",
       " 'initial_list_status',\n",
       " 'out_prncp',\n",
       " 'out_prncp_inv',\n",
       " 'total_pymnt',\n",
       " 'total_pymnt_inv',\n",
       " 'total_rec_prncp',\n",
       " 'total_rec_int',\n",
       " 'total_rec_late_fee',\n",
       " 'recoveries',\n",
       " 'collection_recovery_fee',\n",
       " 'last_pymnt_d',\n",
       " 'last_pymnt_amnt',\n",
       " 'next_pymnt_d',\n",
       " 'last_credit_pull_d',\n",
       " 'collections_12_mths_ex_med',\n",
       " 'mths_since_last_major_derog',\n",
       " 'policy_code',\n",
       " 'not_compliant',\n",
       " 'status',\n",
       " 'inactive_loans',\n",
       " 'bad_loans',\n",
       " 'emp_length_num',\n",
       " 'grade_num',\n",
       " 'sub_grade_num',\n",
       " 'delinq_2yrs_zero',\n",
       " 'pub_rec_zero',\n",
       " 'collections_12_mths_zero',\n",
       " 'short_emp',\n",
       " 'payment_inc_ratio',\n",
       " 'final_d',\n",
       " 'last_delinq_none',\n",
       " 'last_record_none',\n",
       " 'last_major_derog_none']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(loans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we should see that we have some feature columns that have to do with grade of the loan, annual income, home ownership status, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loans['grade'].apply(pd.value_counts).T.stack().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the target column\n",
    "\n",
    "The target column (label column) of the dataset that we are interested in is called `bad_loans`. In this column **1** means a risky (bad) loan **0** means a safe  loan.\n",
    "\n",
    "In order to make this more intuitive and consistent with the lectures, we reassign the target to be:\n",
    "* **+1** as a safe  loan, \n",
    "* **-1** as a risky (bad) loan. \n",
    "\n",
    "We put this in a new column called `safe_loans`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1   -1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: safe_loans, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# safe_loans =  1 => safe\n",
    "# safe_loans = -1 => risky\n",
    "loans['safe_loans'] = loans['bad_loans'].apply(lambda x : +1 if x==0 else -1)\n",
    "loans = loans.drop('bad_loans', 1)\n",
    "loans['safe_loans'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now, let us explore the distribution of the column `safe_loans`. This gives us a sense of how many safe and risky loans are present in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD8CAYAAACLrvgBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJFUzNCRJ1QwNSVK1/wdPGGz0sYKLXgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1cc59438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "loans['safe_loans'].hist(bins=10)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAELCAYAAAAlTtoUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAEbxJREFUeJzt3X+snuVdx/H3x1YmYxk/RoezRYuu\ncTLMHByhOjU6FihsWTHZIotKg7jGhTmnJsrUDNz8sWVGlDjROipFlzGCUxrHrA2bmT8G6ymwMUDk\nuE04guNs7eomiazz6x/PVX3SPj3n6nlKnwPn/UqenPv+3td139/THPic+8fznFQVkiT1+IZJNyBJ\neuYwNCRJ3QwNSVI3Q0OS1M3QkCR1MzQkSd0MDUlSN0NDktTN0JAkdVs56QaOtlNPPbXWrl076TYk\n6Rll9+7dX6yqVQuNe9aFxtq1a5menp50G5L0jJLk33rGeXlKktTN0JAkdTM0JEndDA1JUrcFQyPJ\n1iRPJPnMUO2UJDuTPNy+ntzqSXJdkpkkn05y9tCcTW38w0k2DdXPSXJfm3Ndksx3DEnS5PScadwI\nbDiodhVwR1WtA+5o6wAXAevaazNwPQwCALgaOA84F7h6KASub2MPzNuwwDEkSROyYGhU1ceBPQeV\nNwLb2vI24JKh+k01cCdwUpIXARcCO6tqT1XtBXYCG9q251fVJ2rwJwRvOmhfo44hSZqQxd7TOK2q\nHgdoX1/Y6quBR4fGzbbafPXZEfX5jiFJmpCjfSM8I2q1iPqRHTTZnGQ6yfTc3NyRTpckdVrsO8K/\nkORFVfV4u8T0RKvPAqcPjVsDPNbqP3xQ/e9afc2I8fMd4xBVtQXYAjA1NXXEoSNpyDUnTrqDZ5dr\n9k26g6NqsWca24EDT0BtAm4bql/WnqJaD+xrl5Z2ABckObndAL8A2NG2fSXJ+vbU1GUH7WvUMSRJ\nE7LgmUaSDzA4Szg1ySyDp6DeBdyS5ArgEeD1bfjtwMXADPAkcDlAVe1J8k5gVxv3jqo6cHP9TQye\n0Doe+Eh7Mc8xJEkTsmBoVNUbDrPp/BFjC7jyMPvZCmwdUZ8GzhpR/9KoY0iSJsd3hEuSuhkakqRu\nhoYkqZuhIUnqZmhIkroZGpKkboaGJKmboSFJ6mZoSJK6GRqSpG6GhiSpm6EhSepmaEiSuhkakqRu\nhoYkqZuhIUnqZmhIkroZGpKkboaGJKmboSFJ6mZoSJK6GRqSpG6GhiSpm6EhSepmaEiSuhkakqRu\nhoYkqZuhIUnqZmhIkroZGpKkboaGJKmboSFJ6mZoSJK6jRUaSX4+yf1JPpPkA0m+KckZSe5K8nCS\nDyY5ro19TlufadvXDu3nba3+UJILh+obWm0myVXj9CpJGt+iQyPJauAtwFRVnQWsAC4F3g1cW1Xr\ngL3AFW3KFcDeqnoxcG0bR5Iz27yXAhuAP0yyIskK4L3ARcCZwBvaWEnShIx7eWolcHySlcBzgceB\nVwK3tu3bgEva8sa2Ttt+fpK0+s1V9d9V9TlgBji3vWaq6rNV9RRwcxsrSZqQRYdGVf078DvAIwzC\nYh+wG/hyVe1vw2aB1W15NfBom7u/jX/BcP2gOYerHyLJ5iTTSabn5uYW+y1JkhYwzuWpkxn85n8G\n8C3ACQwuJR2sDkw5zLYjrR9arNpSVVNVNbVq1aqFWpckLdI4l6deBXyuquaq6mvAh4DvB05ql6sA\n1gCPteVZ4HSAtv1EYM9w/aA5h6tLkiZknNB4BFif5Lnt3sT5wAPAx4DXtTGbgNva8va2Ttv+0aqq\nVr+0PV11BrAO+CSwC1jXnsY6jsHN8u1j9CtJGtPKhYeMVlV3JbkVuBvYD9wDbAE+DNyc5Dda7YY2\n5Qbgz5LMMDjDuLTt5/4ktzAInP3AlVX1dYAkbwZ2MHgya2tV3b/YfiVJ48vgl/1nj6mpqZqenp50\nG9Iz1zUnTrqDZ5dr9k26gy5JdlfV1ELjfEe4JKmboSFJ6mZoSJK6GRqSpG6GhiSpm6EhSepmaEiS\nuhkakqRuhoYkqZuhIUnqZmhIkroZGpKkboaGJKmboSFJ6mZoSJK6GRqSpG6GhiSpm6EhSepmaEiS\nuhkakqRuhoYkqZuhIUnqZmhIkroZGpKkboaGJKmboSFJ6mZoSJK6GRqSpG6GhiSpm6EhSepmaEiS\nuhkakqRuY4VGkpOS3Jrkn5M8mOT7kpySZGeSh9vXk9vYJLkuyUySTyc5e2g/m9r4h5NsGqqfk+S+\nNue6JBmnX0nSeMY90/h94G+q6iXAy4AHgauAO6pqHXBHWwe4CFjXXpuB6wGSnAJcDZwHnAtcfSBo\n2pjNQ/M2jNmvJGkMiw6NJM8Hfgi4AaCqnqqqLwMbgW1t2Dbgkra8EbipBu4ETkryIuBCYGdV7amq\nvcBOYEPb9vyq+kRVFXDT0L4kSRMwzpnGtwNzwJ8muSfJ+5KcAJxWVY8DtK8vbONXA48OzZ9ttfnq\nsyPqkqQJGSc0VgJnA9dX1cuB/+L/L0WNMup+RC2ifuiOk81JppNMz83Nzd+1JGnRxgmNWWC2qu5q\n67cyCJEvtEtLtK9PDI0/fWj+GuCxBeprRtQPUVVbqmqqqqZWrVo1xrckSZrPokOjqv4DeDTJd7bS\n+cADwHbgwBNQm4Db2vJ24LL2FNV6YF+7fLUDuCDJye0G+AXAjrbtK0nWt6emLhvalyRpAlaOOf9n\ngfcnOQ74LHA5gyC6JckVwCPA69vY24GLgRngyTaWqtqT5J3ArjbuHVW1py2/CbgROB74SHtJkiZk\nrNCoqnuBqRGbzh8xtoArD7OfrcDWEfVp4KxxepQkHT2+I1yS1M3QkCR1MzQkSd0MDUlSN0NDktTN\n0JAkdTM0JEndDA1JUjdDQ5LUzdCQJHUzNCRJ3QwNSVI3Q0OS1M3QkCR1MzQkSd0MDUlSN0NDktTN\n0JAkdTM0JEndDA1JUjdDQ5LUzdCQJHUzNCRJ3QwNSVI3Q0OS1M3QkCR1MzQkSd0MDUlSN0NDktTN\n0JAkdTM0JEndDA1JUjdDQ5LUbezQSLIiyT1J/rqtn5HkriQPJ/lgkuNa/TltfaZtXzu0j7e1+kNJ\nLhyqb2i1mSRXjdurJGk8R+NM4+eAB4fW3w1cW1XrgL3AFa1+BbC3ql4MXNvGkeRM4FLgpcAG4A9b\nEK0A3gtcBJwJvKGNlSRNyFihkWQN8GrgfW09wCuBW9uQbcAlbXljW6dtP7+N3wjcXFX/XVWfA2aA\nc9trpqo+W1VPATe3sZKkCRn3TOP3gF8C/qetvwD4clXtb+uzwOq2vBp4FKBt39fG/1/9oDmHq0uS\nJmTRoZHkNcATVbV7uDxiaC2w7Ujro3rZnGQ6yfTc3Nw8XUuSxjHOmcYrgNcm+TyDS0evZHDmcVKS\nlW3MGuCxtjwLnA7Qtp8I7BmuHzTncPVDVNWWqpqqqqlVq1aN8S1Jkuaz6NCoqrdV1ZqqWsvgRvZH\nq+rHgY8Br2vDNgG3teXtbZ22/aNVVa1+aXu66gxgHfBJYBewrj2NdVw7xvbF9itJGt/KhYccsV8G\nbk7yG8A9wA2tfgPwZ0lmGJxhXApQVfcnuQV4ANgPXFlVXwdI8mZgB7AC2FpV9z8N/UqSOmXwy/6z\nx9TUVE1PT0+6DemZ65oTJ93Bs8s1+ybdQZcku6tqaqFxviNcktTN0JAkdTM0JEndDA1JUjdDQ5LU\nzdCQJHUzNCRJ3QwNSVI3Q0OS1M3QkCR1MzQkSd0MDUlSN0NDktTN0JAkdTM0JEndDA1JUjdDQ5LU\nzdCQJHUzNCRJ3QwNSVI3Q0OS1M3QkCR1MzQkSd0MDUlSN0NDktTN0JAkdTM0JEndDA1JUjdDQ5LU\nzdCQJHVbOekGlqu1V3140i08a3z+Xa+edAvSsuGZhiSp26JDI8npST6W5MEk9yf5uVY/JcnOJA+3\nrye3epJcl2QmyaeTnD20r01t/MNJNg3Vz0lyX5tzXZKM881KksYzzpnGfuAXq+q7gPXAlUnOBK4C\n7qiqdcAdbR3gImBde20GrodByABXA+cB5wJXHwiaNmbz0LwNY/QrSRrTokOjqh6vqrvb8leAB4HV\nwEZgWxu2DbikLW8EbqqBO4GTkrwIuBDYWVV7qmovsBPY0LY9v6o+UVUF3DS0L0nSBByVexpJ1gIv\nB+4CTquqx2EQLMAL27DVwKND02Zbbb767Ii6JGlCxg6NJM8D/gJ4a1X953xDR9RqEfVRPWxOMp1k\nem5ubqGWJUmLNFZoJPlGBoHx/qr6UCt/oV1aon19otVngdOHpq8BHlugvmZE/RBVtaWqpqpqatWq\nVeN8S5KkeYzz9FSAG4AHq+p3hzZtBw48AbUJuG2ofll7imo9sK9dvtoBXJDk5HYD/AJgR9v2lSTr\n27EuG9qXJGkCxnlz3yuAnwTuS3Jvq/0K8C7gliRXAI8Ar2/bbgcuBmaAJ4HLAapqT5J3ArvauHdU\n1Z62/CbgRuB44CPtJUmakEWHRlX9A6PvOwCcP2J8AVceZl9bga0j6tPAWYvtUZJ0dPmOcElSN0ND\nktTN0JAkdTM0JEndDA1JUjdDQ5LUzdCQJHUzNCRJ3QwNSVI3Q0OS1M3QkCR1MzQkSd0MDUlSN0ND\nktTN0JAkdTM0JEndDA1JUjdDQ5LUzdCQJHUzNCRJ3QwNSVI3Q0OS1M3QkCR1MzQkSd0MDUlSN0ND\nktTN0JAkdTM0JEndDA1JUjdDQ5LUzdCQJHUzNCRJ3QwNSVK3JR8aSTYkeSjJTJKrJt2PJC1nSzo0\nkqwA3gtcBJwJvCHJmZPtSpKWryUdGsC5wExVfbaqngJuBjZOuCdJWraWemisBh4dWp9tNUnSBKyc\ndAMLyIhaHTIo2QxsbqtfTfLQ09rV8nIq8MVJNzGfvHvSHWhClvzPJgC/Pup/Y0vSt/UMWuqhMQuc\nPrS+Bnjs4EFVtQXYcqyaWk6STFfV1KT7kA7mz+ZkLPXLU7uAdUnOSHIccCmwfcI9SdKytaTPNKpq\nf5I3AzuAFcDWqrp/wm1J0rK1pEMDoKpuB26fdB/LmJf9tFT5szkBqTrkvrIkSSMt9XsakqQlxNCQ\nJHUzNCRJ3QwNLSjJ8ybdg6SlwdBQjwcm3YB0OEkun3QPy4lPTwmAJL9wuE3Ar1bVKceyH6lXkkeq\n6lsn3cdyseTfp6Fj5reA9wD7R2zzjFQTleTTh9sEnHYse1nuDA0dcDfwV1W1++ANSX56Av1Iw04D\nLgT2HlQP8E/Hvp3ly9DQAZcDXxouJPnmqvoPwA+F06T9NfC8qrr34A1J/u7Yt7N8eU9Dh5Xk7qo6\ne9J9SFo6vFat+Txj/hCApGPD0NB8/mTSDUhaWrw8JUnq5pmGJKmboSFJ6mZoSJK6GRrSEUjykiT3\nJrknyXcc4dzPJzn16epNOhYMDenIXALcVlUvr6p/nXQz0rFmaGjZS3JCkg8n+VSSzyT5sSRvT7Kr\nrW/JwMXAW4GfTvKxNvcnknyynX38cZIVncf8hbbvzyR561D9r5LsTnJ/ks1D9a8m+c3W451JTmv1\n17d9fCrJx4/uv4x0KENDgg3AY1X1sqo6C/gb4A+q6nvb+vHAa6rqduCPgGur6keSfBfwY8Arqup7\ngK8DP77QwZKcw+BjW84D1gNvTPLytvmnquocBh/d8pYkL2j1E4A7q+plwMeBN7b624ELW/21Y/47\nSAsyNCS4D3hVkncn+cGq2gf8SJK7ktwHvBJ46Yh55wPnALuS3NvWv73jeD8A/GVV/VdVfRX4EPCD\nbdtbknwKuBM4HVjX6k8x+PwlgN3A2rb8j8CNSd4IdJ3lSOPwAwu17FXVv7Tf/i8GfjvJ3wJXAlNV\n9WiSa4BvGjE1wLaqetsRHnLkx7Mk+WHgVcD3VdWT7YP4Dhz3a/X/78T9Ou2/3ar6mSTnAa8G7k3y\nPVX1JaSniWcaWvaSfAvwZFX9OfA7wIEPafxi+1O3rzvM1DuA1yV5YdvPKUm+reOQHwcuSfLcJCcA\nPwr8PXAisLcFxksYXLpaqPfvqKq7qurtwBcZnJ1ITxvPNCT4buA9Sf4H+BrwJgZPSd0HfB7YNWpS\nVT2Q5NeAv03yDW3ulcC/zXewqro7yY3AJ1vpfVV1T5IHgJ9pf3DoIQaXqBbyniTrGJy93AF8qmOO\ntGh+9pQkqZuXpyRJ3bw8JR1lSe4CnnNQ+Ser6r5J9CMdTV6ekiR18/KUJKmboSFJ6mZoSJK6GRqS\npG6GhiSp2/8CIR29SIBKUd4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1a28eeb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot for a categorical column\n",
    "loans.groupby('safe_loans').size().plot(kind='bar')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should have:\n",
    "* Around 81% safe loans\n",
    "* Around 19% risky loans\n",
    "\n",
    "It looks like most of these loans are safe loans (thankfully). But this does make our problem of identifying risky loans challenging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features for the classification algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, we will be using a subset of features (categorical and numeric). The features we will be using are **described in the code comments** below. If you are a finance geek, the [LendingClub](https://www.lendingclub.com/) website has a lot more details about these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = ['grade',                     # grade of the loan\n",
    "            'sub_grade',                 # sub-grade of the loan\n",
    "            'short_emp',                 # one year or less of employment\n",
    "            'emp_length_num',            # number of years of employment\n",
    "            'home_ownership',            # home_ownership status: own, mortgage or rent\n",
    "            'dti',                       # debt to income ratio\n",
    "            'purpose',                   # the purpose of the loan\n",
    "            'term',                      # the term of the loan\n",
    "            'last_delinq_none',          # has borrower had a delinquincy\n",
    "            'last_major_derog_none',     # has borrower had 90 day or worse rating\n",
    "            'revol_util',                # percent of available credit being used\n",
    "            'total_rec_late_fee',        # total late fees received to day\n",
    "           ]\n",
    "\n",
    "target = 'safe_loans'                   # prediction target (y) (+1 means safe, -1 is risky)\n",
    "\n",
    "# Extract the feature columns and target column\n",
    "loans = loans[features + [target]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What remains now is a **subset of features** and the **target** that we will use for the rest of this notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into training and validation sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the data into training and validation sets using an 80/20 split and specifying `seed=1` so everyone gets the same results.\n",
    "\n",
    "**Note**: In previous assignments, we have called this a **train-test split**. However, the portion of data that we don't train on will be used to help **select model parameters** (this is known as model selection). Thus, this portion of data should be called a **validation set**. Recall that examining performance of various potential models (i.e. models with different parameters) should be on validation set, while evaluation of the final selected model should always be on test data. Typically, we would also save a portion of the data (a real test set) to test our final model on or use cross-validation on the training set to select our final model. But for the learning purposes of this assignment, we won't do that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then follow the following steps:\n",
    "\n",
    "Apply one-hot encoding to loans. Your tool may have a function for one-hot encoding. Alternatively, see #7 for implementation hints.\n",
    "\n",
    "Load the JSON files into the lists train_idx and validation_idx.\n",
    "\n",
    "Perform train/validation split using train_idx and validation_idx. In Pandas, for instance:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encoding\n",
    "\n",
    "7.. For scikit-learn's decision tree implementation, it requires numerical values for it's data matrix. This means you will have to turn categorical variables into binary features via one-hot encoding. The next assignment has more details about this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>short_emp</th>\n",
       "      <th>emp_length_num</th>\n",
       "      <th>dti</th>\n",
       "      <th>last_delinq_none</th>\n",
       "      <th>last_major_derog_none</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>total_rec_late_fee</th>\n",
       "      <th>safe_loans</th>\n",
       "      <th>grade_A</th>\n",
       "      <th>grade_B</th>\n",
       "      <th>...</th>\n",
       "      <th>purpose_house</th>\n",
       "      <th>purpose_major_purchase</th>\n",
       "      <th>purpose_medical</th>\n",
       "      <th>purpose_moving</th>\n",
       "      <th>purpose_other</th>\n",
       "      <th>purpose_small_business</th>\n",
       "      <th>purpose_vacation</th>\n",
       "      <th>purpose_wedding</th>\n",
       "      <th>term_ 36 months</th>\n",
       "      <th>term_ 60 months</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>27.65</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>83.7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>8.72</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>98.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>16.97</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>11.20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28.3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   short_emp  emp_length_num    dti  last_delinq_none  last_major_derog_none  \\\n",
       "0          0              11  27.65                 1                      1   \n",
       "1          1               1   1.00                 1                      1   \n",
       "2          0              11   8.72                 1                      1   \n",
       "3          0              11  20.00                 0                      1   \n",
       "4          0               4  11.20                 1                      1   \n",
       "\n",
       "   revol_util  total_rec_late_fee  safe_loans  grade_A  grade_B  \\\n",
       "0        83.7                0.00           1        0        1   \n",
       "1         9.4                0.00          -1        0        0   \n",
       "2        98.5                0.00           1        0        0   \n",
       "3        21.0               16.97           1        0        0   \n",
       "4        28.3                0.00           1        1        0   \n",
       "\n",
       "        ...         purpose_house  purpose_major_purchase  purpose_medical  \\\n",
       "0       ...                     0                       0                0   \n",
       "1       ...                     0                       0                0   \n",
       "2       ...                     0                       0                0   \n",
       "3       ...                     0                       0                0   \n",
       "4       ...                     0                       0                0   \n",
       "\n",
       "   purpose_moving  purpose_other  purpose_small_business  purpose_vacation  \\\n",
       "0               0              0                       0                 0   \n",
       "1               0              0                       0                 0   \n",
       "2               0              0                       1                 0   \n",
       "3               0              1                       0                 0   \n",
       "4               0              0                       0                 0   \n",
       "\n",
       "   purpose_wedding  term_ 36 months  term_ 60 months  \n",
       "0                0                1                0  \n",
       "1                0                0                1  \n",
       "2                0                1                0  \n",
       "3                0                1                0  \n",
       "4                1                1                0  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_loans=pd.get_dummies(loans)\n",
    "temp_loans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read the index documents\n",
    "train_idx = pd.read_json('module-5-assignment-1-train-idx.json')\n",
    "validation_idx = pd.read_json('module-5-assignment-1-validation-idx.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37224, 68)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pull train and test data from products data using the index docs\n",
    "train_data = temp_loans.loc[train_idx.values.reshape((-1,))]\n",
    "validation_data = temp_loans.loc[validation_idx.values.reshape((-1,))]\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9284, 68)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test another way to pull validation data\n",
    "valid_data=temp_loans.loc[validation_idx[0]]\n",
    "valid_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use decision tree to build a classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.. Now, let's use the built-in scikit learn decision tree learner (sklearn.tree.DecisionTreeClassifier) to create a loan prediction model on the training data. To do this, you will need to import sklearn, sklearn.tree, and numpy.\n",
    "\n",
    "Note: You will have to first convert the SFrame into a numpy data matrix, and extract the target labels as a numpy array (Hint: you can use the .to_numpy() method call on SFrame to turn SFrames into numpy arrays). See the API for more information. Make sure to set max_depth=6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_train=train_data['safe_loans']\n",
    "ft=train_data.columns\n",
    "ft=ft.drop('safe_loans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=6,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "decision_tree_model=tree.DecisionTreeClassifier(max_depth=6)\n",
    "decision_tree_model.fit(train_data[ft],output_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10.. Also train a tree using with max_depth=2. Call this model small_model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_model=tree.DecisionTreeClassifier(max_depth=2)\n",
    "small_model.fit(train_data[ft],output_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Visualizing a learned model (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "10a.. For this optional section, we would like to see what the small learned tree looks like. If you are using scikit-learn and have the package Graphviz, then you will be able to perform this section. If you are using a different software, try your best to follow along.\n",
    "\n",
    "Visualize small_model in the software of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dot_data=tree.export_graphviz(small_model,out_file=None,feature_names=train_data[ft].columns,rounded=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph=graphviz.Source(dot_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<graphviz.files.Source object at 0x1a164cd588>\n"
     ]
    }
   ],
   "source": [
    "print(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let's consider two positive and two negative examples from the validation set and see what the model predicts. We will do the following:\n",
    "\n",
    "Predict whether or not a loan is safe.\n",
    "\n",
    "Predict the probability that a loan is safe.\n",
    "\n",
    "11.. First, let's grab 2 positive examples and 2 negative examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 68)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "19    1\n",
       "79    1\n",
       "24   -1\n",
       "41   -1\n",
       "Name: safe_loans, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_safe_loans = validation_data[validation_data[target] == 1]\n",
    "validation_risky_loans = validation_data[validation_data[target] == -1]\n",
    "\n",
    "sample_validation_data_risky = validation_risky_loans[0:2]\n",
    "sample_validation_data_safe = validation_safe_loans[0:2]\n",
    "\n",
    "sample_validation_data = sample_validation_data_safe.append(sample_validation_data_risky)\n",
    "print(sample_validation_data.shape)\n",
    "sample_validation_data_ft = sample_validation_data[sample_validation_data.columns.difference(['safe_loans'])]\n",
    "sample_validation_data_tt = sample_validation_data['safe_loans']\n",
    "sample_validation_data_ft\n",
    "sample_validation_data_tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use his sample data\n",
    "sample_out=sample_validation_data['safe_loans']\n",
    "sample_feat=sample_validation_data[sample_validation_data.columns.drop('safe_loans')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_validation_data_ft.to_csv('sample_validation_data_ft.csv')\n",
    "sample_feat.to_csv('sample_feat.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: float64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare sample_validation_data_ft and sample_feat\n",
    "diff_sample = ((sample_validation_data_ft-sample_feat)**2).sum()\n",
    "diff_sample[diff_sample !=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 67)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_validation_data_ft.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12.. Now, we will use our model to predict whether or not a loan is likely to default. For each row in the sample_validation_data, use the decision_tree_model to predict whether or not the loan is classified as a safe loan. (Hint: if you are using scikit-learn, you can use the .predict() method)\n",
    "\n",
    "Quiz Question: What percentage of the predictions on sample_validation_data did decision_tree_model get correct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -1, -1,  1])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree_model.predict(sample_validation_data_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, -1, -1,  1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for Daniel to check\n",
    "decision_tree_model.predict(sample_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: the percentage of the predictions on sample_validation_data did decision_tree_model get correct:50%\n"
     ]
    }
   ],
   "source": [
    "print('Answer: the percentage of the predictions on sample_validation_data did decision_tree_model get correct:50%' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore probability predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13.. For each row in the sample_validation_data, what is the probability (according decision_tree_model) of a loan being classified as safe? (Hint: if you are using scikit-learn, you can use the .predict_proba() method)\n",
    "\n",
    "Quiz Question: Which loan has the highest probability of being classified as a safe loan?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dti</th>\n",
       "      <th>emp_length_num</th>\n",
       "      <th>grade_A</th>\n",
       "      <th>grade_B</th>\n",
       "      <th>grade_C</th>\n",
       "      <th>grade_D</th>\n",
       "      <th>grade_E</th>\n",
       "      <th>grade_F</th>\n",
       "      <th>grade_G</th>\n",
       "      <th>home_ownership_MORTGAGE</th>\n",
       "      <th>...</th>\n",
       "      <th>sub_grade_F4</th>\n",
       "      <th>sub_grade_F5</th>\n",
       "      <th>sub_grade_G1</th>\n",
       "      <th>sub_grade_G2</th>\n",
       "      <th>sub_grade_G3</th>\n",
       "      <th>sub_grade_G4</th>\n",
       "      <th>sub_grade_G5</th>\n",
       "      <th>term_ 36 months</th>\n",
       "      <th>term_ 60 months</th>\n",
       "      <th>total_rec_late_fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>11.18</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>16.85</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>13.97</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>16.33</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      dti  emp_length_num  grade_A  grade_B  grade_C  grade_D  grade_E  \\\n",
       "19  11.18              11        0        1        0        0        0   \n",
       "79  16.85              10        0        0        0        1        0   \n",
       "24  13.97               3        0        0        0        1        0   \n",
       "41  16.33              11        1        0        0        0        0   \n",
       "\n",
       "    grade_F  grade_G  home_ownership_MORTGAGE         ...          \\\n",
       "19        0        0                        0         ...           \n",
       "79        0        0                        0         ...           \n",
       "24        0        0                        0         ...           \n",
       "41        0        0                        1         ...           \n",
       "\n",
       "    sub_grade_F4  sub_grade_F5  sub_grade_G1  sub_grade_G2  sub_grade_G3  \\\n",
       "19             0             0             0             0             0   \n",
       "79             0             0             0             0             0   \n",
       "24             0             0             0             0             0   \n",
       "41             0             0             0             0             0   \n",
       "\n",
       "    sub_grade_G4  sub_grade_G5  term_ 36 months  term_ 60 months  \\\n",
       "19             0             0                1                0   \n",
       "79             0             0                1                0   \n",
       "24             0             0                0                1   \n",
       "41             0             0                1                0   \n",
       "\n",
       "    total_rec_late_fee  \n",
       "19                 0.0  \n",
       "79                 0.0  \n",
       "24                 0.0  \n",
       "41                 0.0  \n",
       "\n",
       "[4 rows x 67 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_validation_data_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.53630646,  0.46369354],\n",
       "       [ 0.53630646,  0.46369354],\n",
       "       [ 0.53630646,  0.46369354],\n",
       "       [ 0.4440545 ,  0.5559455 ]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree_model.predict_proba(sample_validation_data_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  1])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree_model.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.34156543  0.65843457]\n",
      " [ 0.53630646  0.46369354]\n",
      " [ 0.64750958  0.35249042]\n",
      " [ 0.20789474  0.79210526]]\n",
      "[-1  1]\n",
      "[ 1 -1 -1  1]\n",
      "19    1\n",
      "79    1\n",
      "24   -1\n",
      "41   -1\n",
      "Name: safe_loans, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# calculate prediction probability using sample_feat\n",
    "print(decision_tree_model.predict_proba(sample_feat))\n",
    "print(decision_tree_model.classes_)\n",
    "print(decision_tree_model.predict(sample_feat))\n",
    "print(sample_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:  The fourth loan has the highest probability of being classified as a safe loan\n"
     ]
    }
   ],
   "source": [
    "print('Answer: ', 'The fourth loan has the highest probability of being classified as a safe loan')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checkpoint: Can you verify that for all the predictions with probability >= 0.5, the model predicted the label +1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Yes\n"
     ]
    }
   ],
   "source": [
    "print('Answer: Yes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tricky predictions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14.. Now, we will explore something pretty interesting. For each row in the sample_validation_data, what is the probability (according to small_model) of a loan being classified as safe?\n",
    "\n",
    "Quiz Question: Notice that the probability preditions are the exact same for the 2nd and 3rd loans. Why would this happen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.59255339,  0.40744661],\n",
       "       [ 0.59255339,  0.40744661],\n",
       "       [ 0.59255339,  0.40744661],\n",
       "       [ 0.59255339,  0.40744661]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_model.predict_proba(sample_validation_data_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.41896585,  0.58103415],\n",
       "       [ 0.59255339,  0.40744661],\n",
       "       [ 0.59255339,  0.40744661],\n",
       "       [ 0.23120112,  0.76879888]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate prediction probability using sample_feat\n",
    "small_model.predict_proba(sample_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  1])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_model.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Visualize the prediction on a tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Quiz Question: Based on the visualized tree, what prediction would you make for this data point (according to small_model)? (If you don't have Graphviz, you can answer this quiz question by executing the next part.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "15.. Now, verify your prediction by examining the prediction made using small_model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Evaluating accuracy of the decision tree model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Recall that the accuracy is defined as follows:\n",
    "$$\n",
    "\\mbox{accuracy} = \\frac{\\mbox{# correctly classified examples}}{\\mbox{# total examples}}\n",
    "$$\n",
    "\n",
    "Let us start by evaluating the accuracy of the `small_model` and `decision_tree_model` on the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16.. Evaluate the accuracy of small_model and decision_tree_model on the training data. (Hint: if you are using scikit-learn, you can use the .score() method)\n",
    "\n",
    "Checkpoint: You should see that the small_model performs worse than the decision_tree_model on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64052761659144641"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree_model.score(train_data[ft],output_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.61350204169353106"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_model.score(train_data[ft],output_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17.. Now, evaluate the accuracy of the small_model and decision_tree_model on the entire validation_data, not just the subsample considered above.\n",
    "\n",
    "Quiz Question: What is the accuracy of decision_tree_model on the validation set, rounded to the nearest .01?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67,)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_valid=validation_data['safe_loans']\n",
    "ftv=validation_data.columns\n",
    "ftv=ftv.drop('safe_loans')\n",
    "ftv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: the accurray of decision_tree_model on the vaidation set 0.64\n"
     ]
    }
   ],
   "source": [
    "print('Answer: the accurray of decision_tree_model on the vaidation set', np.round(decision_tree_model.score(validation_data[ftv],output_valid),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: the accurray of small_model on the vaidation set 0.62\n"
     ]
    }
   ],
   "source": [
    "print('Answer: the accurray of small_model on the vaidation set', np.round(small_model.score(validation_data[ftv],output_valid),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating accuracy of a complex decision tree model\n",
    "\n",
    "Here, we will train a large decision tree with `max_depth=10`. This will allow the learned tree to become very deep, and result in a very complex model. Recall that in lecture, we prefer simpler models with similar predictive power. This will be an example of a more complicated model which has similar predictive power, i.e. something we don't want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18.. Using sklearn.tree.DecisionTreeClassifier, train a decision tree with maximum depth = 10. Call this model big_model.\n",
    "\n",
    "19.. Evaluate the accuracy of big_model on the training set and validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66379217709004945"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_model=tree.DecisionTreeClassifier(max_depth=10)\n",
    "big_model.fit(train_data[ft],output_train)\n",
    "big_model.score(train_data[ft],output_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62634640241275308"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_model.score(validation_data[ftv],output_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62634640241275308"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test another way to calculate accurray score for big model based on validation data\n",
    "score2 = big_model.score(valid_data[valid_data.columns.drop('safe_loans')],valid_data['safe_loans'])\n",
    "score2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checkpoint: We should see that big_model has even better performance on the training set than decision_tree_model did on the training set.\n",
    "\n",
    "Quiz Question: How does the performance of big_model on the validation set compare to decision_tree_model on the validation set? Is this a sign of overfitting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: yes\n"
     ]
    }
   ],
   "source": [
    "print('Answer: yes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantifying the cost of mistakes\n",
    "\n",
    "Every mistake the model makes costs money. In this section, we will try and quantify the cost of each mistake made by the model.\n",
    "\n",
    "Assume the following:\n",
    "\n",
    "* **False negatives**: Loans that were actually safe but were predicted to be risky. This results in an oppurtunity cost of losing a loan that would have otherwise been accepted. \n",
    "* **False positives**: Loans that were actually risky but were predicted to be safe. These are much more expensive because it results in a risky loan being given. \n",
    "* **Correct predictions**: All correct predictions don't typically incur any cost.\n",
    "\n",
    "\n",
    "Let's write code that can compute the cost of mistakes made by the model. Complete the following 4 steps:\n",
    "1. First, let us compute the predictions made by the model.\n",
    "1. Second, compute the number of false positives.\n",
    "2. Third, compute the number of false negatives.\n",
    "3. Finally, compute the cost of mistakes made by the model by adding up the costs of true positives and false positives.\n",
    "\n",
    "Quiz Question: Let's assume that each mistake costs us money: a false negative costs $10,000, while a false positive positive costs $20,000. What is the total cost of mistakes made by decision_tree_model on validation_data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let us make predictions on `validation_data` using the `decision_tree_model`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_valid=validation_data['safe_loans']\n",
    "ftv=validation_data.columns\n",
    "ftv=ftv.drop('safe_loans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9284,)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = decision_tree_model.predict(validation_data[ftv])\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# another way to make prediction - based on valid data\n",
    "predictions2 = decision_tree_model.predict(valid_data[valid_data.columns.drop('safe_loans')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**False positives** are predictions where the model predicts +1 but the true label is -1. Complete the following code block for the number of false positives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24     0\n",
       "41     2\n",
       "60     0\n",
       "93     0\n",
       "132    2\n",
       "Name: safe_loans, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff = predictions-output_valid\n",
    "diff.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 5906, -2: 1717, 2: 1661})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "counter = Counter(diff)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1661"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# My first way to calcualte false positives based on validation data\n",
    "counter.get(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# My second way to calculate false positives based on validation data\n",
    "false_pos=np.sum((predictions==1)&(output_valid==-1))\n",
    "false_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Another way to calculate false negatives based on valid data\n",
    "false_pos2=np.sum((predictions2==1)&(valid_data['safe_loans']==-1))\n",
    "false_pos2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**False negatives** are predictions where the model predicts -1 but the true label is +1. Complete the following code block for the number of false negatives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# My first way to calcualte false negatives based on validation data\n",
    "counter.get(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# My second way to calculate false negatives based on validation data\n",
    "false_neg=np.sum((predictions==-1)&(output_valid==1))\n",
    "false_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Another way to calculate false negatives based on valid data\n",
    "false_neg2=np.sum((predictions2==-1)&(valid_data['safe_loans']==1))\n",
    "false_neg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = (false_pos*20000)+(false_neg*10000)\n",
    "print('Answer: the cost is: ', cost)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
